{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c1ee61-fb05-4adf-9f92-2c81602500fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "import warnings\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import wandb\n",
    "import timm\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4'\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41864203-6a9d-4c94-ad00-8d07429cc6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(random_seed: int):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f60f83c-632e-4c3b-adec-2c37773d3e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### HYPER PARAMETER\n",
    "\n",
    "SEED = 0\n",
    "CNT = 0\n",
    "IMG_SIZE = (150, 150) # width, height\n",
    "DROP_RATE = 0.5\n",
    "BATCH_SIZE = 1\n",
    "EPOCH = 1000\n",
    "PATIENCE = 20\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 5e-5\n",
    "PRINT_EVERY = 10\n",
    "\n",
    "GPU_IDX = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b290eb8-5bf1-44a8-b258-f817af8e38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e1450fc-496c-4cf3-a933-66367cfb9a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_padding(img):\n",
    "    height, width, _ = img.shape\n",
    "    img_width, img_height = IMG_SIZE\n",
    "    fill_value = (0, 0, 0)\n",
    "    if width / height == img_width / img_height:\n",
    "        img = cv2.resize(img, (IMG_SIZE))\n",
    "    elif width / height < img_width / img_height:\n",
    "        tmp_width = math.ceil(width / (height / img_height))\n",
    "        img = cv2.resize(img, (tmp_width, img_height))\n",
    "        to_add = img_width - tmp_width\n",
    "        left = to_add // 2\n",
    "        right = to_add - left\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, left, right, cv2.BORDER_CONSTANT, value=fill_value)\n",
    "    else:\n",
    "        tmp_height = math.ceil(height / (width / img_width))\n",
    "        img = cv2.resize(img, (img_width, tmp_height))\n",
    "        to_add = img_height - tmp_height\n",
    "        top = to_add // 2\n",
    "        bottom = to_add - top\n",
    "        img = cv2.copyMakeBorder(img, top, bottom, 0, 0, cv2.BORDER_CONSTANT, value=fill_value)\n",
    "    return img\n",
    "\n",
    "def get_preprocessing():\n",
    "    _transform = [\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a17b42-95eb-41e4-9fea-c675c1d2c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolypDataset(Dataset):\n",
    "    def __init__(self, file_list, label_list, preprocessing=False):\n",
    "        self.file_list = file_list\n",
    "        self.label_list = label_list\n",
    "        self.preprocessing = get_preprocessing() if preprocessing else None\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    def __getitem__(self, idx):\n",
    "        global SEED, CNT\n",
    "        img_path = self.file_list[idx]\n",
    "        xmin, xmax, ymin, ymax = df.loc[df['img_path']==img_path, ['xmin', 'xmax', 'ymin', 'ymax']].values[0]\n",
    "        img = cv2.imread(img_path)\n",
    "        img_h, img_w, _ = img.shape\n",
    "        img = img[ymin:ymax, xmin:xmax, :]\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = add_padding(img)\n",
    "        if self.preprocessing:\n",
    "                sample = self.preprocessing(image=img)\n",
    "                img = sample['image']\n",
    "        label = self.label_list[idx]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa0df8d-d2cb-4cec-92db-e2d4d6f692ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = timm.create_model('resnet50', pretrained=True, num_classes=1024, drop_rate=DROP_RATE)\n",
    "class ResNet_fc(nn.Module):\n",
    "    def __init__(self, _backbone, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        backbone = copy.deepcopy(_backbone)\n",
    "        self.backbone = backbone\n",
    "        self.classifier = nn.Linear(in_features=1024, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "target_layers = ['conv1', 'layer1.2.conv3', 'layer2.3.conv3', 'layer3.5.conv3', 'layer4.2.conv3', 'global_pool', 'fc', 'classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f850bd27-e144-4230-9c8e-05546f809b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'dlfeature_path'\n",
    "model_path = 'model_path_pth'\n",
    "\n",
    "if os.path.isdir(SAVE_PATH):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(SAVE_PATH)\n",
    "for name in target_layers:\n",
    "    dir_path = f'{SAVE_PATH}/{name}/'\n",
    "    if os.path.isdir(dir_path):\n",
    "        continue\n",
    "    else:\n",
    "        os.mkdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "354d8726-f06e-4106-bbe5-d0b4c389308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c494fff55148eb8d8c7cbb5ae1369a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409cead5ba3542a6b062649e0bc0608a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c37b9ec5f04ebaab6bfc5a4d4c242a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d7bb0a43ba4239ba5794c2fd267523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fcc6cab6414fe69e1d66d837a0ebea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209890f926ea4414ad9d2f9e7779a0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(f'/workspace/data4/changwoo/Colonoscopy/XAI_test/XAI_test.csv')\n",
    "img_list = df['img_path'].tolist()\n",
    "label_list = df['label'].tolist()\n",
    "test_data = PolypDataset(img_list, label_list, box_noise=False, light_gen=False, augmentation=False, preprocessing=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "model = ResNet_fc(backbone, num_classes=2)\n",
    "model.load_state_dict(torch.load(f'/workspace/data4/changwoo/Colonoscopy/weights/EndoAI/SRgen_CutMix_0.001/fold_{fold}.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "model = model.to(GPU_IDX)\n",
    "\n",
    "for layer_idx, target_module_name in enumerate(tqdm(target_layers)):\n",
    "    class model_forward(nn.Module):\n",
    "        def __init__(self,model):\n",
    "            super(model_forward,self).__init__()\n",
    "            self.model = model\n",
    "            self.model.eval()\n",
    "            if layer_idx == 0:\n",
    "                self.model.backbone.act1.register_forward_hook(self.forward_hook)\n",
    "            elif layer_idx == 1:\n",
    "                self.model.backbone.layer1[-1].act3.register_forward_hook(self.forward_hook)\n",
    "            elif layer_idx == 2:\n",
    "                self.model.backbone.layer2[-1].act3.register_forward_hook(self.forward_hook)\n",
    "            elif layer_idx == 3:\n",
    "                self.model.backbone.layer3[-1].act3.register_forward_hook(self.forward_hook)\n",
    "            elif layer_idx == 4:\n",
    "                self.model.backbone.layer4[-1].act3.register_forward_hook(self.forward_hook)\n",
    "            elif layer_idx == 5:\n",
    "                self.model.backbone.global_pool.register_forward_hook(self.forward_hook)\n",
    "            elif layer_idx == 6:\n",
    "                self.model.backbone.fc.register_forward_hook(self.forward_hook)\n",
    "            elif layer_idx == 7:\n",
    "                self.model.classifier.register_forward_hook(self.forward_hook)\n",
    "            else:\n",
    "                print(target_layers[layer_idx])\n",
    "\n",
    "        def forward_hook(self, _, input, output):\n",
    "            self.forward_result = output\n",
    "        def forward(self,x):\n",
    "            x = self.model(x)\n",
    "            return self.forward_result\n",
    "    \n",
    "    model_forward = model_forward(model)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data_idx, (data, label) in enumerate(test_dataloader):\n",
    "            data = data.to(GPU_IDX)\n",
    "            data = model_forward(data)[0].detach().cpu().numpy()\n",
    "            data_path = img_list[data_idx]\n",
    "            fname = data_path.split('/')[-1].split('.')[0]\n",
    "            save_path = f'/workspace/data4/changwoo/Colonoscopy/XAI_test/feature_map/fold_{fold}/{target_module_name}/{fname}.npy'\n",
    "            np.save(save_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06b957-cae3-4b8c-a086-47bbc718ecdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
