{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "import warnings\n",
    "import random\n",
    "import easydict\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import wandb\n",
    "import timm\n",
    "import libtiff\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "libtiff.libtiff_ctypes.suppress_warnings()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(random_seed: int):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "\n",
    "def add_padding(img):\n",
    "    height, width, _ = img.shape\n",
    "    img_width, img_height = IMG_SIZE\n",
    "    fill_value = (0, 0, 0)\n",
    "    if width / height == img_width / img_height:\n",
    "        img = cv2.resize(img, (IMG_SIZE))\n",
    "    elif width / height < img_width / img_height:\n",
    "        tmp_width = math.ceil(width / (height / img_height))\n",
    "        img = cv2.resize(img, (tmp_width, img_height))\n",
    "        to_add = img_width - tmp_width\n",
    "        left = to_add // 2\n",
    "        right = to_add - left\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, left, right, cv2.BORDER_CONSTANT, value=fill_value)\n",
    "    else:\n",
    "        tmp_height = math.ceil(height / (width / img_width))\n",
    "        img = cv2.resize(img, (img_width, tmp_height))\n",
    "        to_add = img_height - tmp_height\n",
    "        top = to_add // 2\n",
    "        bottom = to_add - top\n",
    "        img = cv2.copyMakeBorder(img, top, bottom, 0, 0, cv2.BORDER_CONSTANT, value=fill_value)\n",
    "    return img\n",
    "\n",
    "def get_preprocessing():\n",
    "    _transform = [\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "IMG_SIZE = (150, 150) \n",
    "GPU_IDX = 4\n",
    "seed_everything(SEED)\n",
    "\n",
    "model_path = 'pretrained_model_pth'\n",
    "data_path = 'Data_csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_PATH_ = 'CAM_savepath'\n",
    "for folder in ['mask', 'overlay']:\n",
    "    SAVE_PATH = f'{SAVE_PATH_}/{folder}/'\n",
    "    if os.path.isdir(SAVE_PATH):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = timm.create_model('resnet50', pretrained=True, num_classes=1024, drop_rate=DROP_RATE)\n",
    "class ResNet_fc(nn.Module):\n",
    "    def __init__(self, _backbone, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        backbone = copy.deepcopy(_backbone)\n",
    "        self.backbone = backbone\n",
    "        self.classifier = nn.Linear(in_features=1024, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "img_list = df['img_path'].tolist()\n",
    "label_list = df['label'].tolist()\n",
    "prob_list = df['prob'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ResNet_fc(backbone, num_classes=2)\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "model.eval()\n",
    "model = model.to(GPU_IDX)\n",
    "target_layers = [model.backbone.layer4[-1]]\n",
    "c0_target = [ClassifierOutputTarget(0)]\n",
    "c1_target = [ClassifierOutputTarget(1)]\n",
    "\n",
    "for idx in tqdm(range(len(img_list))):\n",
    "    img_path = img_list[idx]\n",
    "    img_name = img_path.split('/')[-1].split('.')[0]\n",
    "    label = label_list[idx]\n",
    "    prob = prob_list[idx]\n",
    "    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n",
    "    xmin, xmax, ymin, ymax = df.loc[df['img_path']==img_path, ['xmin', 'xmax', 'ymin', 'ymax']].values[0]\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    \n",
    "    img = img[ymin:ymax, xmin:xmax, :]\n",
    "    img = add_padding(img)\n",
    "    input_tensor = get_preprocessing()(image=img)['image'].unsqueeze(0).to(GPU_IDX)\n",
    "    rgb_img = img / 255.\n",
    "    if prob >= 0.5:\n",
    "        c1_grayscale_cam = cam(input_tensor=input_tensor, targets=c1_target)\n",
    "        c1_grayscale_cam = c1_grayscale_cam[0, :]\n",
    "        c1_visualization = show_cam_on_image(rgb_img, c1_grayscale_cam, use_rgb=True)\n",
    "        c1_grayscale_cam = (c1_grayscale_cam * 255).astype(np.uint8)\n",
    "    else:\n",
    "        c0_grayscale_cam = cam(input_tensor=input_tensor, targets=c0_target)\n",
    "        c0_grayscale_cam = c0_grayscale_cam[0, :]\n",
    "        c0_visualization = show_cam_on_image(rgb_img, c0_grayscale_cam, use_rgb=True)\n",
    "        c0_grayscale_cam = (c0_grayscale_cam * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
